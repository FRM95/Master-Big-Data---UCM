---
title: 'Módulo minería de datos: Cliente a la fuga'
author: "Miguel Moreno Mardones"
date: "8 de Marzo de 2022"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
subtitle: 'Master Big Data: Data Science - UCM'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introducción

En este documento trataremos de comprender la relación que tiene la fuga de clientes en una empresa telefónica en base al historial de algunas de sus variables recogidas a lo largo de un tiempo no determinado. No trataremos de explicar el funcionamiento de cualquier modelo de regresión, ya sea lineal o logística así como cualquier concepto relacionado con la inspección o interpretación de datos o el lenguaje de R, por lo que se recomienda disponer de una base previa para comprender este documento. La variable fuga es una variable de carácter dicotómico, con valores 0 y 1, donde 0 representa la no fuga (permanencia) y 1 la fuga del cliente de la compañía. Por lo tanto nuestro cometido será ayudar a la empresa mediante el mejor ajuste posible de un modelo de regresión logística (la variable a predecir es binaria).

```{r paquetes, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
#Cargamos todas las librerías y paquetes necesarios para trabajar
source('Funciones_R.R')
paquetes(c('questionr','psych','car','corrplot','ggplot2',"gridExtra",'kableExtra','dplyr','DMwR2','caret','pROC'))
FugaClientes_Training <- readRDS("C:/../FugaClientes_Training.RDS")
#Realizamos una copia del dataset original sobre la que trabajaremos
FClientesTrain_Moded <- FugaClientes_Training
```

## Paso previo: Inspección inicial del dataset

Comenzamos realizando algunas comprobaciones de las características más relevantes de nuestro dataset que nos permitirán conocer el escenario inicial. Para ser mas cuidadoso, trabajaremos con una copia dela rchivo original, para evitar modificaciones no deseadas. Hay que recordar que el dataset deberá estar cargado en nuestro workspace. Con str(FClientesTrain_Moded) mostramos los datos.

```{r lectura datos, echo = FALSE}
#Realizamos una inspección de los datos
str(FClientesTrain_Moded)
```

A priori no encontramos nada distinguible, no existen categorías de variables que no estén representadas, por lo que no es necesaria ninguna unión de categorías de variables. Algunas columnas poseen valores conocidos como NA o perdidos que tendremos que tratar posteriormente. Mediante la siguiente función buscaremos algún valor extremo u outlier en algunas de las columnas numéricas.

```{r outliers, echo = FALSE}
valAtip <- data.frame(sort(
  round(sapply(Filter(
    is.numeric, FClientesTrain_Moded),function(nOut) atipicosAmissing(
      nOut)[[2]])/nrow(FClientesTrain_Moded)*100,3), decreasing = T))
names(valAtip)<-"% Outliers en variables numericas"

#Llamamos a la función
valAtip
```

Comprobamos la proporción de valores perdidos (NA) en cada una de las variables de las columnas numéricas. De igual manera, podemos conocer la cantidad de registros que poseen algún valor perdido, esto nos dará una idea de la cantidad de información que podríamos llegar a perder si nos deshacemos de ellos. 

```{r perdidos, echo = FALSE}
prop_missingsVars <- apply(is.na(FClientesTrain_Moded),2,mean)
valPerd <- data.frame(sort(prop_missingsVars*100, decreasing = T))
names(valPerd)<-"% Missing por Variable"
#Llamamos a la función
valPerd
porcentajePerdi <- apply(is.na(FClientesTrain_Moded),1,mean)
#Porcentaje de registros sin valores perdidos (NA)
(sum(porcentajePerdi==0)/length(porcentajePerdi))*100
#Porcentaje de registros con al menos un valor perdido (NA)
(sum(porcentajePerdi>0)/length(porcentajePerdi))*100
```

Por tanto, si no realizamos ninguna modificación de estos NA, podríamos llegar a perder hasta un 40% de la información de los registros, un valor muy alto con el que trabajar y realizar predicciones. 

De manera adicional, no esta mal comprobar la aleatoriedad de estos valores perdidos, por ello, aplicamos una función para observar la correlación entre estos NA.  

```{r correlacionl, out.width = "50%"}
#Realizamos un gráfico de correlaciones
corrplot(cor(is.na(FClientesTrain_Moded[colnames(
  FClientesTrain_Moded)[colSums(is.na(FClientesTrain_Moded))>0]])),method = "ellipse",type = "upper") 
```

Al no encontrar ningún patrón aparente, podríamos definir como "aleatorios" la aparición de estos valores NA, sin guardar ninguna relación entre las variables del dataset.

## Paso 1: Manipulación de los datos y transformación de las variables

En este apartado realizamos los ajustes de las columnas del dataset a gusto del programador y del estudio. En mi caso, no me gusta poseer valores altos en las columnas de tipo Factor, por lo que transformaré la variable ID a tipo char(). Tampoco me gusta con trabajar con variables Yes/no, por lo que una posible solución puede ser transformar las variables dicotómicas Yes/No a 0/1.

```{r transformaciones, echo = FALSE, warning=FALSE}
#Transformo la variable ID de tipo Factor a tipo carácter
FClientesTrain_Moded$ID <- as.character(FClientesTrain_Moded$ID)
#Conocemos las columnas que poseen un valor dicotomico y las transformamos a 0/1
for (i in c(4,5,7,8,10,11,12,13,14,15,17)) {
  levels(FClientesTrain_Moded[,i]) <- c(0,1) 
}
```

Para el caso de los NA sobre las variables cuantitativas tomamos el camino de la imputación aleatoria, ya que guarda una distribución muy similar a la original presentada por el dataset con valores perdidos. Podríamos haber realizado una eliminación de estos registros (arriesgandonos a la gran perdida de información como vimos antes) u optar por la vía de la media o mediana, son opciones igual de viables.

```{r imputacion cualitativa, warning=FALSE}
#Volvemos a crear una copia de la copia para realizar las imputaciones
FClientesTrain_Moded3 <- FClientesTrain_Moded

#Opcion: Imputacion de cuantitativas por aleatorio sobre las variables cuantitativas con NA
FClientesTrain_Moded3[,as.vector(which(sapply(FClientesTrain_Moded3, class)=="numeric"))]<-
sapply(Filter(is.numeric, FClientesTrain_Moded3),function(x) ImputacionCuant(x,"aleatorio"))
```

Podemos ver las distribuciones originales y las imputadas mediante histogramas para comprobar que las distribuciones siguen siendo muy similares, todo ello mediante la función hist(). Sigo pensando que el factor aleatorio no centra tanto los valores, por lo que la consideramos la imputación más óptima para nuestro desarrollo del ejercicio.

```{r distribuciones cuantitativas imputacion, warning=FALSE, echo = FALSE}
#Creamos un layout que nos permita ver todos los gráficos
Conf3x2 = matrix(c(1:6), nrow=2, byrow=TRUE)
layout(Conf3x2)

#Creamos los histogramas de las distribuciones con variables cualitativas originales y las imputadas aleatoriamente
hist(FClientesTrain_Moded$Antig.fc.edad, main = 'Histograma 1' ,xlab = 'Antigüedad del contrato')
hist(FClientesTrain_Moded$FacturaMes, main = 'Histograma 2' ,xlab = 'Factura mensual')
hist(FClientesTrain_Moded$FacturaTotal, main = 'Histograma 3' ,xlab = 'Factura total')
hist(FClientesTrain_Moded3$Antig.fc.edad, main = 'Histograma 4' ,xlab = 'Antigüedad del contrato imputada')
hist(FClientesTrain_Moded3$FacturaMes, main = 'Histograma 5' ,xlab = 'Factura mensual imputada')
hist(FClientesTrain_Moded3$FacturaTotal, main = 'Histograma 6' ,xlab = 'Factura total imputada')
```

Respecto a las variables cualitativas que poseen valores NA podemos emplear de igual manera la imputación aleatoria, generar una nueva categoría o simplemente eliminarlos. Descartamos la opción de prescindir de la información, por lo que para la variable género creamos un valor "Unknown" o desconocido, y para los demás casos realizamos la misma imputación aleatoria. 

Para el caso de género, nos podemos permitir crear una nueva categoría ya que veremos que no resulta ser una variable relevante a tener en cuenta en el estudio. De igual manera, no considero positivo realizar una distinción de fuga de clientes en base al género, por lo que con esta transformación además nos ahorramos pérdida de información.

```{r imputacion cuantitativa, warning=FALSE, message=F, echo = FALSE}
#Cambiamos el valor de genero a caracter, añadimos la nueva categoria y finalmente la convertimos de nuevo a factor
FClientesTrain_Moded3$Genero <- as.character(FClientesTrain_Moded3$Genero)
FClientesTrain_Moded3$Genero[is.na(FClientesTrain_Moded3$Genero)] <- "Unknown"
FClientesTrain_Moded3$Genero <- as.factor(FClientesTrain_Moded3$Genero)

#Aplicamos a las columnas cualitativas con NA el valor de aleatoriedad
FClientesTrain_Moded3[,as.vector(which(sapply(FClientesTrain_Moded3, class)=="factor"))]<-sapply(
  Filter(is.factor, FClientesTrain_Moded3),function(x) ImputacionCuali(x,"aleatorio"))

FClientesTrain_Moded3[,as.vector(which(sapply(FClientesTrain_Moded3, class)=="character"))] <- lapply(
  FClientesTrain_Moded3[,as.vector(which(sapply(FClientesTrain_Moded3, class)=="character"))] , factor)

#Comprobamos que no quede ningun NA, si es así, volvemos a pasar el código
if (any(is.na(FClientesTrain_Moded3))){
FClientesTrain_Moded3[,as.vector(which(sapply(FClientesTrain_Moded3, class)=="numeric"))]<-sapply(
  Filter(is.numeric, FClientesTrain_Moded3),function(x) ImputacionCuant(x,"aleatorio"))
}

sum(is.na(FClientesTrain_Moded3))

#En ocasiones el código realiza transformaciones de mas, nos aseguramos que las variables siguen con los valores
FClientesTrain_Moded3$ID <- as.character(FClientesTrain_Moded3$ID)
```

Guardamos en nuestro espacio de trabajo el dataset finalmente depurado y listo para el ejercicio.
```{r dataset depurado, warning=FALSE, echo=FALSE}
#Guardamos finalmente el dataset depurado
FugaClientes_TrainingDep <- FClientesTrain_Moded3
saveRDS(FugaClientes_TrainingDep, file = "FugaClientes_TrainingDep.rds")
```

## Paso 2: Importancia de las variables respecto a la variable objetivo

En la introducción vimos que aplicar un modelo de regresión logístico es la opción para poder predecir la fuga de los clientes de nuestra compañía. Si bien es cierto que la creación de un único modelo es viable, es una idea muy pobre y no concuerda con la realidad de los estudios elaborados en el ámbito profesional. Por eso, crearemos un alto número de modelos con diferentes ecuaciones de regresión logística, para así compararlos entre sí mediante validación cruzada (como hemos visto en el modulo) y posteriormente decidir cual es el más indicado. 

```{r ver importancia de variables, warning=FALSE, echo = FALSE}
#Guardamos la variable fuga para poder trabajar con ella de manera externa
objetivo <- FugaClientes_TrainingDep$Fuga 
```

Pero antes de ello realizamos un pequeño estudio descriptivo de la relación de las variables predictoras con la variable respuesta. Mediante la introducción de variables aleatorias de control veremos si realmente existe importancia, ya que  aquellas que queden por debajo de estas variables de control podrían ser desechadas para el estudio.

```{r ver vcramer, warning=FALSE, out.width = "50%"}
#Introducimos las variables aleatorias de control
FugaClientes_TrainingDep$aleatorio <- runif(nrow(FugaClientes_TrainingDep))
FugaClientes_TrainingDep$aleatorio2 <- runif(nrow(FugaClientes_TrainingDep))
#Guardamos una copia del dataset sin la variable fuga para ver unicamente las variables predictoras 
input <- FugaClientes_TrainingDep[,-c(21)] 
#Grafico VCramer para ver la relacion de todas variables con el objetivo de fuga
#Decidimos quitar ID del grafico ya que no es relevante
graficoVcramer(input[,-c(1)],objetivo)
```

Mediante VCramer podemos observar como Contrato, Antigüedad del contrato, Servicio de internet y Metodo de pago poseen mas relevancia respecto al resto de variables. Por lo que no sería descabellado contar con ellas a priori para los posibles futuros modelos a generar. Como vemos, la variable Genero carece de importancia como discutiamos anteriormente. Sin embargo, podemos recolectar más información para comprobar la relevancia de estas. 

```{r ver importancia de variables cualitativas, echo = FALSE, out.width = "50%", warning=FALSE}
#Cantidad de clientes fieles y fugados respecto al tipo de contrato, metodo de pago..
table(FugaClientes_TrainingDep$Contrato,FugaClientes_TrainingDep$Fuga)
table(FugaClientes_TrainingDep$MetodoPago,FugaClientes_TrainingDep$Fuga)
table(FugaClientes_TrainingDep$Int_serv,FugaClientes_TrainingDep$Fuga)

#Relacion de variables cualitativas respecto a la variable binaria objetivo Fuga
mosaico_targetbinaria(input$Contrato,objetivo,"Mosaico Contratro")
mosaico_targetbinaria(input$Int_serv,objetivo,"Mosaico Servicio de internet")
mosaico_targetbinaria(input$MetodoPago,objetivo,"Mosaico Metodo de pago")

#Veo curioso comparar la variable cualitativa Soporte tecnico con Fuga
mosaico_targetbinaria(input$Soporte_tecnico,objetivo,"Mosaico Soporte Tecnico")
```

¿Qué podemos sacar de estos mosaicos?:

- En primer lugar hay una aparente mayor fuga de clientes en contratos mensuales, respecto a los anuales. Logicamente, un cliente que no posee un contrato de permanencia anual en una compañía tiene más probabilidad de abandonar la compañía a lo largo del tiempo.

- Al parecer, hay una gran mayoría de clientes fugados que tenían contratado el servicio de fibra óptica de internet cuando abandonaron la compañia... esto podría ser muy interesante de cara al análisis, ¿es posible que el cliente no esté contento con dicho servicio de internet?, ¿quizás tiene una relación de precio-calidad elevada?. La compañía debería vigilar esta variable.

- En relación a los metodos de pago, los pagos electrónicos no automáticos parecen estar relacionados con los clientes dados a la fuga, mientras que las transacciones automáticas parecen acogher a los clientes fieles.

- Respecto a los demás servicios adicionales como Seguridad, Peliculas, Antivirus o Streaming no encontramos una gran diferencia de distribución, quizás no son un factor condicionante para abandonar la compañía. Es por eso que no los representamos en los mosaicos. 

Realizamos algo similar para las variables cuantitativas mediante diagramas de cajas e histogramas al ser variables continuas:

```{r ver importancia de variables cuantitativas, warning=FALSE, out.width = "50%"}
#Graficos de la Factura mensual respecto a fuga
boxplot_targetbinaria(input$FacturaMes,objetivo,"Factura mensual")
hist_targetbinaria(input$FacturaMes,objetivo,"Factura mensual")

#Graficos de la Factura total respecto a fuga
boxplot_targetbinaria(input$FacturaTotal,objetivo,"Factura total")
hist_targetbinaria(input$FacturaTotal,objetivo,"Factura total")

#Graficos de la Antigüedad respecto a fuga
boxplot_targetbinaria(input$Antig.fc.edad,objetivo,"Antigüedad del contrato")
hist_targetbinaria(input$Antig.fc.edad,objetivo,"Antigüedad del contrato")
```

- En la Factura mensual observamos una mayor dispersion de valores en los clientes fieles a la compañia (caja roja o valor "0"), mientras que los que abandonan (caja azul o valor "1") suelen acumularse en facturas mensuales más costosas y sin tanta dispersión. Esto puede observarse tambien en el histograma de densidad, donde encontramos un incremento de la curva azul de clientes fugados conforme el coste de la factura aumenta, asi mismo, hay un gran pico de clientes fieles en facturas baratas, pero la curva de densidad se ve reducidad conforme la factura mensual aumenta.

- La factura total no llega a ser tan representativa como puede observarse en el diagrama de cajas y en el histograma. Aquí ambas curvas se superponen a lo largo del eje X salvo al principio, donde hay un pico azul en la densidad ya que los clientes fugados deberían tener una factura total menor que la de un cliente que suele permanecer más tiempo.

- La antigüedad del contrato muestra tambien algo evidente. Los clientes leales poseen una mayor antigüedad que los fugados (curva roja estable a lo largo del eje X), un gran pico de fugados aparece al principio ya que suelen rescindir sus contratos de manera más prematura. 

Todo esto puede conducirnos a varias preguntas. ¿Se ve reducida la tarifa mensual en los contratos más largos o con mayor antigüedad premiando así la permanencia del cliente u ofreciendo  servicios adicionales?. ¿La tarifa mensual para los clientes con contrato mensual va aumentando conforme pasa el tiempo?. ¿Es quizás el contrato mensual demasiado caro?. Hay otras variables que no han sido tenidas en cuenta por el momento, cliente mayor de 65 años, soporte técnico ofrecido.. puede que exista una posible influencia en nuestros datos para predecir la fuga.

## Paso 3: Desarrollo de los distintos modelos

En esta sección se crearán distintos modelos de regresión logística con el objetivo de ir mejorando sus condiciones (cantidad de parametros, valores de pseudoR2, importancia de variables..) conforme se vayan generando más modelos. Es por eso que, cuanto mayor sea el número de modelos, ecuaciones generadas o relaciones distintas entre variables, tendremos una mayor ristra de donde escoger y comparar posteriormente. 

Utilizaremos nuestro dataset depurado FugaClientes_TrainingDep, el cual será dividido en un 80% para la parte de entrenamiento de modelos o training y el restante 20% para la parte de test, donde estos modelos serán probados con otros datos distintos. Es así donde veremos la eficacia de los modelos generados. 

Introducimos así una semilla o generador de números pseudoaleatorios para obtener la mayor aleatoriedad posible en dividir el dataset en training y test. Es recomendable utilizar varios tipos de semillas o seeds. 

```{r division del dataset}
#Semilla para generar el conjunto training y test
set.seed(123456)
trainIndex <- createDataPartition(FugaClientes_TrainingDep$Fuga, p=0.8, list=FALSE)
#Obtenemos dos datasets
input_train <- FugaClientes_TrainingDep[trainIndex,]
input_test <- FugaClientes_TrainingDep[-trainIndex,]
```

Mediante la función glm(), generamos distintos modelos logísticos. Hay que tener en cuenta que a la hora de generarlos hemos eliminado la variable de ID ya que es la única no relevante para nuestro estudio. El primer modelo generado nos sirve de referencia ya que computa todas las variables en la ecuación. Así podremos observar en una primera instancia la importancia de las variables al pseudoR2 o la significancia de las mismas.

```{r modelos generados, out.width = "50%"}
#Modelo 1: con todas las variables salvo ID (columna 1)
modelo1 <- glm(Fuga ~ . , data = input_train[,-c(1)], family=binomial)
#Información del modelo
summary(modelo1)
#Valor de pseudoR2
pseudoR2(modelo1,input_train,"Fuga") 
pseudoR2(modelo1,input_test,"Fuga")
#Importancia de las variables
impVariablesLog(modelo1,"Fuga",input_train) 
```

En el gráfico de importancia en escala logarítmica vemos la influencia de las variables al valor de pseudoR2. Las más relevantes serán de nuevo algunas como el Contrato, Servicio de internet o Antigüedad del contrato del cliente. De igual manera, en el summary del modelo vemos que estas categorías son representadas con "***", lo que concluye que realmente sí son significativas y por lo tanto, afectarán en mayor medida a la variable objetivo fuga. Otras como el Método de pago, Factura mensual, antivirus, Copia de seguridad, Servicio de Streaming, peliculas.. no parecen ser relevantes (valores de la columna Pr no significativos) por lo que no serán tenidas en cuenta en los siguientes modelos.

Los valores de pseudo-R2 de training 0.28 y test 0.25 nos acercan a valores equivalentes a 0.7 en modelos lineales, lo que indica un ajuste óptimo de los datos previos.

Generaremos otro modelo con las tres variables más significativas del modelo referencia

```{r Modelo 2, out.width = "50%"}
#Modelo 2: 
modelo2 <- glm(Fuga ~ Contrato + Int_serv + Antig.fc.edad, data = input_train[,-c(1)], family=binomial)
summary(modelo2)
pseudoR2(modelo2,input_train,"Fuga")
pseudoR2(modelo2,input_test,"Fuga")
impVariablesLog(modelo2,"Fuga",input_train) 
```

Aquí vemos que cobra más importancia el tipo de Servicio de internet que contrata el cliente respecto a las otras dos variables, igualmente ambas tres son realmente significativas por lo que serán tenidas en el restante de modelos generados. Los valores de pseudo-R2 son menores ya que estamos utilziando una menor cantida de variables para predecir la probabilidad de fuga del cliente. Intentaremos encontrar la mejor fórmula que aumente este valor de ajuste.

A partir de aquí, generamos 7 modelos adicionales donde iremos probando la inclusión de otras variables cuantitativas como la Factura Total del cliente o incluso cualitativas como el Método de pago, la contratación del servicio de Soporte técnico o el recibo de Factura electrónica (sin papel). No aplicamos la función de summary para cada uno de ellos para no sobrecargar el documento, si no que realizaremos una lectura general de ellos más adelante.

```{r Generacion de los modelos restantes}
#Modelo 3: 
modelo3 <- glm(Fuga ~  Contrato + Int_serv + Antig.fc.edad + Fact_sinPapel, data = input_train[,-c(1)], family=binomial)

#Modelo 4: 
modelo4 <- glm(Fuga ~  Contrato + Int_serv + Antig.fc.edad + Soporte_tecnico, data = input_train[,-c(1)], family=binomial)

#Modelo 5: 
modelo5 <- glm(Fuga ~  Contrato + Int_serv + Antig.fc.edad + Fact_sinPapel + Soporte_tecnico, data = input_train[,-c(1)], family=binomial)

#Modelo 6: 
modelo6 <- glm(Fuga ~ Contrato + Int_serv + Antig.fc.edad + Fact_sinPapel + MetodoPago, data = input_train[,-c(1)], family=binomial)

#Modelo 7: 
modelo7 <- glm(Fuga ~ Contrato + Int_serv + Antig.fc.edad + Fact_sinPapel + MetodoPago + Soporte_tecnico, data = input_train[,-c(1)], family=binomial)

#Modelo 8: 
modelo8 <- glm(Fuga ~ Contrato*FacturaTotal + Int_serv + Antig.fc.edad + MetodoPago, data = input_train[,-c(1)], family=binomial)

#Modelo 9: 
modelo9 <- glm(Fuga ~  Contrato*FacturaTotal + Int_serv + Antig.fc.edad + MetodoPago + Fact_sinPapel, data = input_train[,-c(1)], family=binomial)

#Recordamos que para obtener la informacion restante de los modelos aplicamos las funciones:
#summary(modeloX)
#pseudoR2(modeloX,input_train,"Fuga")
#pseudoR2(modeloX,input_test,"Fuga")
#impVariablesLog(modeloX,"Fuga",input_train)
```

Una vez generados los modelos observamos los valores de pseudo-R2 generados. Aquellos modelos que posean un aumento de este valor posiblemente estén mejor ajustados, sin embargo algunos tendrán valores superiores para el input_test en comparación con el resto. Es aquí donde reside la habilidad para seleccionar, ya que podemos tener un alto valor de pseudo-R2 en training pero bajo en el test, por lo que nuestro modelo tendrá un buen ajuste para los datos seleccionados de training, pero a la hora de usar este modelo con otros datos nuevos (input_test) puede predecir de peor manera la posibilidad de fuga del cliente, a esto se le llama sobreajuste del modelo.

Además, incluir un gran número de variables en la ecuación dificultará la interpretación del modelo, como es el caso del modelo 7, que tiene 6 variables en su ecuación. Este modelo tiene valores de pseudo-R2 más altos en training: 0.2608 debido al número de variables pero empeora en el test: 0.2543 en comparación con otros que son más sencillos. 

Adicionalemnte, podemos establecer relaciones entre variables cualitativas y cuantitativas como en los modelos 8 y 9, donde relacionamos el contrato del cliente con su factura total. Aquí obtenemos una buena relación de pseudo-R2 en training, 0.2542 en el modelo 8 y 0.2601 para el modelo 9, así como en test, 0.2568 del modelo 8 y 0.2606 en el modelo 9. Sin embargo su ecuación de regresión logística es significativamente más compleja que en el resto.  

El modelo 6 por lo contrario posee valores de pseudo-R2 similares a estos anteriores modelos, pero con una ecuación más sencilla: 0.2577 en training y 0.2525 para el test.

## Paso 4: Validacion y seleccion entre los modelos

Aplicamos el metodo de validación cruzada. Dividimos el dataset depurado en 5 submuestras, formando subconjuntos de training y test pero excluyendo una parte de estas 5. Tras esto se evalurá las partes seleccionadas con las excluidas en cada iteración repitiendo esto 20 veces con distintas semillas para cada partición. Este proceso requiero un alto nivel de computación, pero estaremos evitando el posible sobreajuste y la sombra de la aleatoriedad de comparación de modelos manual. Podríamos dedicar todo un documento a explicar la ejecución del algoritmo, pero con este resumen es más que suficiente.

```{r validacion cruzada, message = FALSE, warning = FALSE}
#Validacion cruzada repetida para elegir entre todos los modelos
#Copiamos de la variable original de fuga 
auxVarObj <- objetivo
#Copiamos el dataset depurado para evitar modificaciones no deseadas
FugaClientes_TrainingDep2 <- FugaClientes_TrainingDep
#Cambiamos los valores de la variable fuga 0/1 por X0/X1 para el algoritmo
FugaClientes_TrainingDep$Fuga <- make.names(FugaClientes_TrainingDep$Fuga) 
#Aplicamos la validacion cruzada
total<-c()
modelos <- sapply(list(modelo1,modelo2,modelo3,modelo4,modelo5,modelo6,modelo7,modelo8,modelo9),formula)
for (i in 1:length(modelos)){
  set.seed(1712)
  vcr <- train(as.formula(modelos[[i]]), data = FugaClientes_TrainingDep,
             method = "glm", family="binomial",metric = "ROC",
             trControl = trainControl(method="repeatedcv", number=5, repeats=20,
                                      summaryFunction=twoClassSummary,
                                      classProbs=TRUE,returnResamp="all")
  )
  total<-rbind(total,data.frame(roc=vcr$resample[,1],modelo=rep(paste("Modelo",i),
  nrow(vcr$resample))))
}
```

Cuando desarrollamos un modelo de regresión logística sobre una variable a objetivo binaria (fuga) obtenemos lo que se conoce como matriz de confusión (2x2), que define el número de observaciones del modelo bien o mal clasificadas. Según esta matriz, un valor de observación podrá ser: Verdadero negativo (el valor real de la variable binaria es 0 y el predicho es 0), Falso positivo (el valor de la variable binaria real es 0 y el predicho es 1), Falso negativo (el valor de la variable binaria real es 1 y el predicho es 0) o Verdadero positivo (el valor de la variable binaria real es 1 y el predicho es 1). Es por eso, que debemos maximizar la capacidad de nuestro modelo para predecir a los verdaderos positivos y a los verdaderos negativos, dando lugar respectivamente a un valor de especificidad y sensibilidad = 1. 

Esta capacidad de predecir una observación como evento (1) o no evento (0) vendrá determinada por un valor de probabilidad donde se considerará esta observación como 1 o 0. Este valor será el que nosotros debemos determinar, en pos de maximizar la precisión del modelo, la tasa de especificidad, sensibilidad, un equilibrio de ambas.. (puede utilizarse la medida de 0.5 para determinar estas observaciones).

Por ello, tras aplicar el algoritmo de validación cruzada, obtendremos el gráfico de cajas y bigotes donde tenemos representados todos los valores del sesgo y la varianza de nuestros modelos bajo la medida ROC. Esta medida muestra la sensibilidad frente al valor de 1-especifidad (tasa de predicción de verdaderos positivos frente a la 1-tasa de predicción de falsos positivos). Por lo que si el valor del eje Y (sensibilidad) se acerca a 1 y el valor del eje X (1-Especificidad) se acerca a 0, significa que estaremos maximizando estos valores. En otras palabras, valoras altos de ROC indican una capacidad de clasificación muy buena, que es lo que realmente buscamos.

```{r medidas ROC, out.width = "50%"}
#Representamos los modelos
boxplot(roc ~ modelo,data=total,main="Área bajo la curva ROC")

#Valores medios de los modelos
aggregate(roc~modelo, data = total, mean) 
aggregate(roc~modelo, data = total, sd)
```

Todos los valores medios de ROC indican un buen ajuste y clasificación, la diferencia entre ellos radica en valores muy pequeños. Parece ser que a partir del modelo 5 todos tienen valores similares a 0.83, por lo que lo lógico sería apuntar a estos modelos. De igual manera, deberemos fijarnos en la medidad de la desviación (sd), a mayor desviación más explicará nuestro modelo. Las mejores opciones podrían ser los modelos 5, 6 y 9. Sin embargo, el modelo 9 poseía una fórmula más compleja que los otros y su valor de ROC sd es menor. El 5 posee un valor medio de ROC un poco menor al 6 pero una variabilidad superior, además contiene en su ecuación la contratación del soporte técnico (cualidad que puede marcar la diferencia a la hora de asegurar la permanencia de los clientes, al menos en la vida real..). El modelo elegido por lo tanto es el modelo 5.


## Paso 5: Punto de corte 

La estimación del punto de corte para decidir el evento (1) o el no evento (0) de las observaciones viene definidido por el valor de probabilidad que adquiera en el rango [0,1]. Hemos dicho que un valor de 0.5 suele utilizarse de manera habitual. No obstante trateremos de establecer el mejor punto de corte posible. 

```{r, out.width = "50%"}
#Histograma de las probabilidades
hist_targetbinaria(predict(modelo5, newdata=input_test,type="response"),input_test$Fuga,"Probabilidad")
#Podemos ver que ambos histogramas se cortan en un valor cercano a 0.3, por lo que el valor del corte podría ser ese
```

Aplicamos la siguiente función para ver que valores de precisión, sensitividad, especificidad.. obtenemos para distintos puntos de corte, tras esto decidiremos el mejor valor.

```{r}
#Valores de precision, especificidad, 
sensEspCorte(modelo5,input_test,"Fuga",0.75,"1")
sensEspCorte(modelo5,input_test,"Fuga",0.5,"1")
sensEspCorte(modelo5,input_test,"Fuga",0.3,"1")
```

El valor de 0.75 ofrece una sensitividad de 0 y especificidad de 1, predice unicamente los valores 0, queda descartado. El valor de 0.5 ofrece una baja sensitividad frente a la especificidad pero una gran precisión, tampoco merece la pena sacrificar una baja sensitividad ya que queremos predecir los 1 (fuga del cliente). El valor 0.3 nos da un gran equilibrio, quizás bajarlo un poco más a 0.29 (vimos en el histograma que el corte no llega a ser 0.3) mejora la predicción.

```{r}
#Punto de corte final
sensEspCorte(modelo5,input_train,"Fuga",0.29,"1")
sensEspCorte(modelo5,input_test,"Fuga",0.29,"1")
```

Aumentamos precisión y sensitividad, tanto en el test como en el training, este valor es el ideal.

```{r}
# Generamos el factor de predicciones con las clases estimadas en el test
pred_test<-factor(ifelse(predict(modelo5,input_test,type = "response")>0.29,1,0)) 
table(pred_test)
#El modelo predice 772 clientes fieles y 498 fugados para los datos de test
```

Generamos la matriz de confusión.

```{r}
# Matriz de confusión
table(input_test$Fuga)
confusionMatrix(pred_test,input_test$Fuga, positive = '1')
```
El modelo predice con una precisión del 74.88% en un intervalo del confianza del 95% (0.724, 0.7725) un total de 258/337 1's o clientes fugados y un total de 693/933 0's o clientes fieles. 

```{r, echo = FALSE}
#Revertimos todos los cambios realizados para la selección del modelo
FugaClientes_TrainingDep$Fuga <- as.factor(FugaClientes_TrainingDep$Fuga)
levels(FugaClientes_TrainingDep$Fuga) <- c(0,1)
#Eliminamos las variables de control
FugaClientes_TrainingDep$aleatorio <- NULL 
FugaClientes_TrainingDep$aleatorio2 <- NULL
```

Creamos el modelo final sobre los datos depurados para obtener unos mejores coeficientes y un ajuste mayor al aplicarlo sobre un dataset de mayor cantidad de datos.

```{r, out.width = "50%"}
#Creamos el modelo final
modeloFinal <- glm(formula(modelo5),data=FugaClientes_TrainingDep,family=binomial)
#Información del modelo
summary(modeloFinal)
#Coeficientes del modelo
coef(modeloFinal)

#Odds ratios del modelo final
epiDisplay::logistic.display(modeloFinal)
```
Los valores de los coeficientes serán los betas de nuestra ecuación de regresión logística, mientras que los Odds ratio será el valor exponencial de esos coeficientes. 

¿Qué conclusiones podemos sacar de los Odds ratios? Debemos tener en cuenta que todas estas probabilidades se extraen de la columna ajustada (adj .OR) y que se mueven siempre en un intervalo de confianza. Por lo que dichos valores podrían variar. Dicho esto, algunas interpretaciones podrían ser las siguientes:

La probabilidad de fuga respecto a la permanencia de un cliente se reduce en un 56% en los clientes con contrato de un años respecto al contrato mes a mes, y del 76% en los clientes de dos años respecto a los mensuales (1 - 0.44 = 0.56 y 1 - 0.24 = 0.76). En cuanto al servicio de internet contratado, la probabilidad de fuga de un cliente es 2.86% superior en aquellos clientes que contratan la fibra óptica respecto a aquellos que solo tienen contratado el ADSL. Además, la fuga se reduce en un 61% si no tienen contratado ningún servicio de internet contratado.

La probabilidad de fuga se reduce en un 35% (rango de IC del 23% al 45%) en los clientes que tienen contratado el servicio técnico, mientras que recibir la factura de manera electrónica (y no en papel) aumenta la probabilidad de fuga en un 1.65% respecto a los clientes que la reciben de manera tradicional.

En cuanto a la variable cualitativa, cada aumento unitario en la antigüedad del contrato mensual de un cliente se produce una reducción de probabilidad de fuga del 3%. 


Como pudimos intuir anteriormente en la exploración de los datos, incluir la contratación del servicio técnico influye bastante la probabilidad de fuga de un cliente. No hablamos de que la compañía ofrece un mal soporte técnico, si no que es posible que se produzcan bastantes problemas o fallos que requieran de este soporte, por lo que aquellos clientes que dispongan de este servicio serán más propensos a permanecer. En cuanto al servicio de internet, aparece un claro problema en la fibra óptica, los clientes fugados tienen contratado en su mayoría este servicio, por lo que puede ser que este no funcione correctamente o su precio no sea el adecuado. Los contratos mensuales como vimos al principio están asociados a una mayor probabilidad de fuga, trabajar en este aspecto y ofrecer unos contratos anuales pueden reducir esta cantidad. De manera obvia, la antigüedad del cliente ofrece aparentemente una mayor sensación de agrado en los clientes, por lo que se debe tener en consideración a los clientes nuevos que entren en la empresa. 

## Paso 6: Aplicación a los datos del Test de la empresa

Finalmente, debemos aplicar nuestro modelo final a los datos otorgados por la empresa que no contienen a la variable fuga.

```{r, echo = FALSE}
#Renombramos el valor de la variable ya que esta definida en FugaClientes_test es distinta
FugaClientes_test <- readRDS("C:/Users/Miguel/Documents/MASTER BIG DATA UCM/Modulos/8 - Mineria de datos/Ejercicio/TAREAM1/FugaClientes_test.RDS")
names(FugaClientes_test)[6] <- "Antig.fc.edad"

#Transformamos a factor las variables del test para poder aplicar nuestro modelo y aquellas con valores YES/NO a 0/1
for (i in c(3,4,5,7,8,10,11,12,13,14,15,17)) {
  FugaClientes_test[,i] <- as.factor(FugaClientes_test[,i])
  levels(FugaClientes_test[,i]) <- c(0,1) 
}

#Creamos un vector con los valores predichos por nuestro modelo Final sobre los datos de test
Fuga_pred <- factor(ifelse(predict(modeloFinal,FugaClientes_test, type = "response")>0.29,1,0))

#Añadimos como columna el vector al dataset FugaClientes_test
FugaClientes_test$Fuga_pred <- Fuga_pred

#Dataset final que guarda los clientes con su ID y el valor de fuga
FugaPredict_MiguelMorenoMardones <- FugaClientes_test[,c(1,21)]
saveRDS(FugaPredict_MiguelMorenoMardones,"FugaPredict_MiguelMorenoMardones.RDS")

```

```{r}
#Dataset final que guarda los clientes con su ID y el valor de fuga
FugaPredict_MiguelMorenoMardones <- FugaClientes_test[,c(1,21)]
saveRDS(FugaPredict_MiguelMorenoMardones,"FugaPredict_MiguelMorenoMardones.RDS")

```

