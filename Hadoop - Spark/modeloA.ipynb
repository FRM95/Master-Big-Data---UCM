{"cells": [{"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "3d01e43162b64c90ce0048e8a23f3b1b", "grade": false, "grade_id": "cell-f8987996be9f1238", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "# Accidentes de tr\u00e1fico en Reino Unido entre 2010 y 2014 \n\n### Disponible en Kaggle en:\nhttps://www.kaggle.com/stefanoleone992/adm-project-road-accidents-in-uk"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "9a6b4dc108ddf890c659e33701965428", "grade": false, "grade_id": "cell-f74d7bfd01811789", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "### Variables y significado"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "4a5a5882319ae0a14393c8d534816a56", "grade": false, "grade_id": "cell-9cfb34982bd4eb04", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* Accident_Index: Accident index\n* Latitude: Accident latitude\n* Longitude: Accident longitude\n* Region: Accident region\n* Urban_or_Rural_Area: Accident area (rural or urban)\n* X1st_Road_Class: Accident road class\n* Driver_IMD_Decile: Road IMD Decile\n* Speed_limit: Road speed limit\n* Road_Type: Road type\n* Road_Surface_Conditions: Road surface condition\n* Weather: Weather\n* High_Wind: High wind\n* Lights: Road lights\n* Datetime: Accident datetime\n* Year: Accident year\n* Season: Accident season\n* Month_of_Year: Accident month\n* Day_of_Month: Accident day of month\n* Day_of_Week: Accident day of week\n* Hour_of_Day: Accident hour of day\n* Number_of_Vehicles: Accident number of vehicles\n* Age_of_Driver: Driver age\n* Age_of_Vehicle: Vehicle age\n* Junction_Detail: Accident junction detail\n* Junction_Location: Accident junction location\n* X1st_Point_of_Impact: Vehicle first point of impact\n* Driver_Journey_Purpose: Driver journey purpose\n* Engine_CC: Vehicle engine power (in CC)\n* Propulsion_Code: Vehicle propulsion code\n* Vehicle_Make: Vehicle brand\n* Vehicle_Category: Vehicle brand category\n* Vehicle_Manoeuvre: Vehicle manoeuvre when accident happened\n* Accident_Severity: Accident severity"}, {"cell_type": "markdown", "metadata": {}, "source": "**Nombre completo del alumno:** Miguel Maria Moreno Mardones "}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "28429bd5e3051f643a72b2e5787231f5", "grade": false, "grade_id": "cell-b4f9c37a2b92d2e6", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "**INSTRUCCIONES**: en cada celda debes responder a la pregunta formulada, asegur\u00e1ndote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del c\u00e1lculo quede guardado exactamente en la variable que ven\u00eda inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). **No olvides borrar la l\u00ednea *raise NotImplementedError()* de cada celda cuando hayas completado la soluci\u00f3n de esa celda y quieras probarla**.\n\nDespu\u00e9s de cada celda evaluable ver\u00e1s una celda con c\u00f3digo. Ejec\u00fatala (no modifiques su c\u00f3digo) y te dir\u00e1 si tu soluci\u00f3n es correcta o no. Adem\u00e1s de esas pruebas, se realizar\u00e1n algunas m\u00e1s (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la soluci\u00f3n correcta o no. Aseg\u00farate de que, al menos, todas las celdas indican que el c\u00f3digo es correcto antes de enviar el notebook terminado."}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "e7764e6064699f591cd2896d2430528e", "grade": false, "grade_id": "cell-69ec0993eeaff3ac", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "### Sobre el dataset anterior (accidents_uk.csv) se pide:"}, {"cell_type": "markdown", "metadata": {}, "source": "* **(1 punto)** Leerlo tratando de que Spark infiera el tipo de dato de cada columna, y cachearlo."}, {"cell_type": "code", "execution_count": 1, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "494ea1492132b3a5e88d7b7b5ea9c9ce", "grade": false, "grade_id": "read_csv", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"data": {"text/plain": "DataFrame[Accident_Index: string, Latitude: double, Longitude: double, Region: string, Urban_or_Rural_Area: string, X1st_Road_Class: string, Driver_IMD_Decile: int, Speed_limit: int, Road_Type: string, Road_Surface_Conditions: string, Weather: string, High_Wind: string, Lights: string, Datetime: timestamp, Year: int, Season: int, Month_of_Year: int, Day_of_Month: int, Day_of_Week: int, Hour_of_Day: double, Number_of_Vehicles: int, Age_of_Driver: int, Age_of_Vehicle: int, Junction_Detail: string, Junction_Location: string, X1st_Point_of_Impact: string, Driver_Journey_Purpose: string, Engine_CC: int, Propulsion_Code: string, Vehicle_Make: string, Vehicle_Category: string, Vehicle_Manoeuvre: string, Accident_Severity: string]"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\naccidentesDF = spark.read.options(header = \"true\", inferSchema = \"true\", delimiter = \",\")\\\n                    .csv(\"gs://ntic-bucket-name-miguel/data/accidents_uk.csv\")\n\naccidentesDF.cache()\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 2, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "fe7160ffc743634220394f78cbf50bc1", "grade": true, "grade_id": "read_csv_test", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "from pyspark.sql.types import DoubleType\nassert(accidentesDF.schema[1].dataType == DoubleType())"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "1295004c825ce57f3f88b725f083e586", "grade": false, "grade_id": "cell-b90f5b934eda250e", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* **(1 punto)** Discretizar la variable **Age_of_Vehicle** utilizando un bucketizer (sin crear un pipeline) en los puntos de corte (0, 2, 5, 10, 15, 20, 35). La discretizaci\u00f3n debe quedar en una nueva columna de tipo Double llamada **Edad_Vehiculo**."}, {"cell_type": "code", "execution_count": 3, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "467714adc92d47c04b7573bd1f1faa06", "grade": false, "grade_id": "bucketize", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEAS EVALUABLES, NO RENOMBRAR LAS VARIABLES\nfrom pyspark.ml.feature import Bucketizer\n\nbucketizer = Bucketizer(splits = [0,2,5,10,15,20,35], inputCol = \"Age_of_Vehicle\", outputCol = \"Edad_Vehiculo\")\naccidentesBucketizedDF = bucketizer.transform(accidentesDF)\n\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 4, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "7c1ac69726ac8effcf1a2124b1e2cd3a", "grade": true, "grade_id": "bucketize_tests", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "assert(\"Edad_Vehiculo\" in accidentesBucketizedDF.columns)\nassert(accidentesBucketizedDF.schema.fields)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "cdd57f341bfabbfbb3c648ec78af5a64", "grade": false, "grade_id": "cell-fc88821f19453a51", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* **(1 punto)** Crear un nuevo DF donde la columna \"Age_of_Driver\" ha sido reemplazada por otra de tipo string en la que los valores 1 y 2 son \"Adolescente\", los valores 3 y 4 por \"Joven\", los valores 5 y 6 por \"Adulto\", y los dem\u00e1s valores se dejan sin modificar."}, {"cell_type": "code", "execution_count": 5, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "c9ee5110f5af1c97a769ec03d3431c3f", "grade": false, "grade_id": "renombrar_edad", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StringType\n\naccidentesAgeDF = accidentesDF.withColumn(\"Age_of_Driver\", F.when(F.col(\"Age_of_Driver\") == 1, \"Adolescente\")\\\n                                                            .when(F.col(\"Age_of_Driver\") == 2, \"Adolescente\")\\\n                                                            .when(F.col(\"Age_of_Driver\") == 3, \"Joven\")\\\n                                                            .when(F.col(\"Age_of_Driver\") == 4, \"Joven\")\\\n                                                            .when(F.col(\"Age_of_Driver\") == 5, \"Adulto\")\\\n                                                            .when(F.col(\"Age_of_Driver\") == 6, \"Adulto\")\\\n                                                            .otherwise(F.col(\"Age_of_Driver\")))\n\n#No need to string column cast after defining conditions\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 6, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "4f33a56b8af18220e6b77664c0f11851", "grade": true, "grade_id": "renombrar_edad_test", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Row(Age_of_Driver='8', count=9195), Row(Age_of_Driver='7', count=13338), Row(Age_of_Driver='Adolescente', count=57174), Row(Age_of_Driver='Adulto', count=67138), Row(Age_of_Driver='Joven', count=104987)]\n"}], "source": "assert(dict(accidentesAgeDF.dtypes)[\"Age_of_Driver\"] == \"string\")\ncollectedDF = accidentesAgeDF.groupBy(\"Age_of_Driver\").count().orderBy(\"count\").collect()\nprint(collectedDF)\nassert((collectedDF[0][\"count\"] == 9195) & (collectedDF[0][\"Age_of_Driver\"] == \"8\"))\nassert((collectedDF[1][\"count\"] == 13338) & (collectedDF[1][\"Age_of_Driver\"] == \"7\"))\nassert((collectedDF[2][\"count\"] == 57174) & (collectedDF[2][\"Age_of_Driver\"] == \"Adolescente\"))\nassert((collectedDF[3][\"count\"] == 67138) & (collectedDF[3][\"Age_of_Driver\"] == \"Adulto\"))\nassert((collectedDF[4][\"count\"] == 104987) & (collectedDF[4][\"Age_of_Driver\"] == \"Joven\"))"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "b805abfe5774032f7cf030b50153b2a8", "grade": false, "grade_id": "cell-a71a6b17b1e0d613", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* **(1 punto)** Partiendo de `accidentesDF`, crear un nuevo DataFrame de una sola fila que contenga, **por este orden de columnas**, el **n\u00famero** de categor\u00edas existentes para el prop\u00f3sito del viaje, para el tipo de maniobra del veh\u00edculo, para las condiciones de la calzada y para la severidad del accidente. Pista: crear las columnas al vuelo con `select`(). Renombrar cada columna de conteo para que se llame igual que la propia columna que estamos contando."}, {"cell_type": "code", "execution_count": 7, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "760ca31245afc350de47c7cd98aa6950", "grade": false, "grade_id": "numero_categorias", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nnumeroCategoriasDF = accidentesDF.select(F.countDistinct(\"Driver_Journey_Purpose\").alias(\"Driver_Journey_Purpose\"),\\\n                                         F.countDistinct(\"Vehicle_Manoeuvre\").alias(\"Vehicle_Manoeuvre\"),\\\n                                         F.countDistinct(\"Road_Surface_Conditions\").alias(\"Road_Surface_Conditions\"),\\\n                                         F.countDistinct(\"Accident_Severity\").alias(\"Accident_Severity\"))\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 8, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "30ebc9730a12379f2bcce1ad04f24e33", "grade": true, "grade_id": "numero_categorias_test", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "assert(len(numeroCategoriasDF.columns) == 4)\nassert(numeroCategoriasDF.count() == 1)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "8b42e836688d46b3680b7ab2dc4d3169", "grade": false, "grade_id": "cell-c5ec05706eccd480", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* **(3 puntos)** Partiendo de `accidentesAgeDF` definido anteriormente, crear un nuevo DataFrame con tantas filas como posibles prop\u00f3sitos de un viaje, y tantas columnas como rangos de edad hab\u00edamos distinguido en dicho DataFrame m\u00e1s una (la del prop\u00f3sito del viaje). Las columnas deben llamarse igual que cada uno de los niveles posibles de rangos de edad. Cada casilla del nuevo DataFrame deber\u00e1 contener el **porcentaje** del n\u00famero de accidentes ocurridos en ese tipo de viaje (fila) para ese rango de edad (columna), medido sobre el *total de accidentes ocurridos para ese tipo de viaje*.\n\nPista: se puede hacer todo en una sola secuencia de transformaciones sin variable auxiliar. Calcular primero el conteo, despu\u00e9s a\u00f1adir una columna con los totales de cada tipo de viaje como la suma de las 5 columnas de conteos, y finalmente reemplazar cada columna de conteo por su porcentaje. No debe utilizarse `when` en ning\u00fan momento, solo aritm\u00e9tica de columnas. Recuerda c\u00f3mo desplegar grupos en varias columnas."}, {"cell_type": "code", "execution_count": 9, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "7098be8996fe3e79691c07ae1552d862", "grade": false, "grade_id": "viajes_por_edad", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nfrom pyspark.sql.functions import col\nfrom pyspark.sql import Window\nviajesPorEdadDF = accidentesAgeDF.groupBy(\"Driver_Journey_Purpose\").pivot(\"Age_of_Driver\").agg(F.count('*'))\\\n                   .withColumn('total', col(\"7\") + col(\"8\") + col(\"Adolescente\") + col(\"Adulto\") + col(\"Joven\"))\\\n                   .select(F.col(\"Driver_Journey_Purpose\"),(F.col(\"7\")/F.col(\"total\")).alias('7'),\\\n                          (F.col(\"8\")/F.col(\"total\")).alias('8'),(F.col(\"Adolescente\")/F.col(\"total\")).alias('Adolescente'),\\\n                          (F.col(\"Adulto\")/F.col(\"total\")).alias('Adulto'),(F.col(\"Joven\")/F.col(\"total\")).alias('Joven'))\n\n#Removed * 100 each cell in viajesPorEdadDF\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 10, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "1e85aec10339652ee69e69997a220ba1", "grade": true, "grade_id": "viajes_por_edad_test", "locked": true, "points": 3, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "assert(len(viajesPorEdadDF.columns) >= 6)\nassert(\"7\" in viajesPorEdadDF.columns)\nassert(\"8\" in viajesPorEdadDF.columns)\nassert(\"Adolescente\" in viajesPorEdadDF.columns)\nassert(\"Joven\" in viajesPorEdadDF.columns)\nassert(\"Adulto\" in viajesPorEdadDF.columns)\nassert(viajesPorEdadDF.columns[0] == \"Driver_Journey_Purpose\")\nassert(viajesPorEdadDF.count() == 5)\ncommuting = viajesPorEdadDF.orderBy(\"Driver_Journey_Purpose\").collect()[0]\nassert(commuting.Driver_Journey_Purpose.startswith(\"Commuting\"))\nassert(abs(commuting['7'] - 0.012527948326649396) < 0.001)\nassert(abs(commuting['8'] - 0.002519785640770) < 0.001)\nassert(abs(commuting.Adolescente - 0.236327501153423) < 0.001)\nassert(abs(commuting.Adulto - 0.2791993469851297) < 0.001)\nassert(abs(commuting.Joven - 0.46942541789402703) < 0.001)"}, {"cell_type": "markdown", "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "49d2b52bb5a2988f54170966f3657b57", "grade": false, "grade_id": "cell-9ebe35c4b4325269", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": "* **(3 puntos)** Unir la informaci\u00f3n obtenida en el paso anterior al DataFrame `accidentesAgeDF`, de manera que **al resultado final se a\u00f1ada una columna nueva llamada `Porcentaje`** que contenga el porcentaje de accidentes que ha habido para ese rango de edad y ese tipo de viaje de entre todos los viajes que ha habido de ese tipo (es decir, el porcentaje adecuado de la tabla anterior). Por ejemplo, si el accidente se produjo en un trayecto de tipo `Commuting...` y la persona es `Joven`, entonces la columna Porcentaje tomar\u00e1 el valor de la columna `Joven` y por tanto tendr\u00e1 el valor 0.46942, pero si la persona es `Adulto`, entonces tomar\u00e1 el valor de la columna `Adulto` el cual ser\u00e1 0.2791993469851297.\n\nPISTA: unir los dos DF mediante join() convencional, y a continuaci\u00f3n, crear la nueva columna `Porcentaje` en el resultado, utilizando `when` para ver cu\u00e1l es el valor que debe tener en cada fila (m\u00e1s concretamente: de qu\u00e9 columna debemos tomarlo) en funci\u00f3n del valor de la columna `Age_of_Driver`. No se necesitan variables intermedias; se puede hacer en una secuencia de transformaciones encadenadas."}, {"cell_type": "code", "execution_count": 11, "metadata": {"deletable": false, "nbgrader": {"cell_type": "code", "checksum": "2e8addac1e30ac1f6a2d5fed36ff4010", "grade": false, "grade_id": "join", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": "# L\u00cdNEA EVALUABLE, NO RENOMBRAR VARIABLES\nfinalDF = viajesPorEdadDF.join(accidentesAgeDF, ['Driver_Journey_Purpose'])\\\n                         .withColumn('Porcentaje',F.when(F.col('Age_of_Driver') == '7',F.col('7'))\\\n                                                   .when(F.col('Age_of_Driver') == '8',F.col('8'))\\\n                                                   .when(F.col('Age_of_Driver') == 'Adolescente',F.col('Adolescente'))\\\n                                                   .when(F.col('Age_of_Driver') == 'Adulto',F.col('Adulto'))\\\n                                                   .when(F.col('Age_of_Driver') == 'Joven',F.col('Joven')))\n\n#Used inner join with list on param: ['column'] to avoid duplicated columns\n#raise NotImplementedError"}, {"cell_type": "code", "execution_count": 12, "metadata": {"deletable": false, "editable": false, "nbgrader": {"cell_type": "code", "checksum": "afede5f5bc886534cae92a88870b9688", "grade": true, "grade_id": "join_tests", "locked": true, "points": 3, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": "def sum_cond(df, column, condition): \n    return(df.where(condition).select(F.sum(column).alias(column)).collect()[0][column])\n    \nassert(\"Porcentaje\" in finalDF.columns)\nassert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adolescente\") - 13344.826819125037) < 0.001)\nassert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Joven\") - 44438.00809518224) < 0.001)\nassert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adulto\") - 18028.24488479408) < 0.001)\nassert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"7\") - 812.0952970292334) < 0.001)\nassert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"8\") - 432.2987413617681) < 0.001)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}}, "nbformat": 4, "nbformat_minor": 2}